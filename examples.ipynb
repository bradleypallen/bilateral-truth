{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factuality_evaluator_rs_sf import UnilateralFactualityEvaluator, BilateralFactualityEvaluator\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = [\n",
    "    {\n",
    "        \"problem\": \"Who was the first man to walk on the Moon?\",\n",
    "        \"answer\": \"Neil Armstrong\"\n",
    "    }, \n",
    "    {\n",
    "        \"problem\": \"Who was the first man to walk on the Moon?\",\n",
    "        \"answer\": \"Pete Conrad\"\n",
    "    }, \n",
    "    {\n",
    "        \"problem\": \"Are penguins birds?\",\n",
    "        \"answer\": \"No\"\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Who was the frobnoz that restified the branks?\",\n",
    "        \"answer\": \"Rutherford B. Hayes\"\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"When was America discovered?\",\n",
    "        \"answer\": \"1492\"\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Did Lee Harvey Oswald act alone in the assassination of John Kennedy?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Is the Holy Trinity one entity or three entities?\",\n",
    "        \"answer\": \"Three\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unilateral_evaluation(example):\n",
    "    unilateral_evaluator = UnilateralFactualityEvaluator(MODEL)\n",
    "    evaluation = unilateral_evaluator.invoke(example)\n",
    "    display(Markdown(f\"## Unilateral\"))\n",
    "    display(Markdown(f\"### Reasoning\"))\n",
    "    display(Markdown(evaluation[\"reasoning\"][0]))\n",
    "    display(Markdown(f\"### Evaluation: {evaluation['evaluation']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_evaluation(example):\n",
    "    bilateral_evaluator = BilateralFactualityEvaluator(MODEL)\n",
    "    evaluation = bilateral_evaluator.invoke(example)\n",
    "    display(Markdown(f\"## Bilateral\"))\n",
    "    display(Markdown(f\"### Verification\"))\n",
    "    display(Markdown(evaluation[\"verification\"][0]))\n",
    "    display(Markdown(f\"### Refutation\"))\n",
    "    display(Markdown(evaluation[\"refutation\"][0]))\n",
    "    display(Markdown(f\"### Evaluation: {evaluation['evaluation']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Who was the first man to walk on the Moon? Neil Armstrong"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Unilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Reasoning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Question: Who was the first man to walk on the Moon?\n",
       "Response: Neil Armstrong\n",
       "\n",
       "Extracted Answer: Neil Armstrong\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively TRUE or FALSE:\n",
       "\n",
       "1. Verify the extracted answer against known facts:\n",
       "   - Neil Armstrong is widely recognized and historically documented as the first man to walk on the Moon during the Apollo 11 mission on July 20, 1969.\n",
       "\n",
       "2. Check for any contradictory information:\n",
       "   - There is no credible contradictory information regarding Neil Armstrong being the first man to walk on the Moon.\n",
       "\n",
       "3. Consider question context and any implied terms:\n",
       "   - The question is straightforward, asking for the identity of the first man to walk on the Moon, which aligns with the historical fact that it was Neil Armstrong.\n",
       "\n",
       "4. Determine if the extracted answer correctly responds to what was asked:\n",
       "   - The extracted answer \"Neil Armstrong\" directly and correctly answers the question.\n",
       "\n",
       "Reasoning:\n",
       "The extracted answer \"Neil Armstrong\" is consistent with historical records and widely accepted facts. There is no credible evidence to dispute this fact, and it directly answers the question asked.\n",
       "\n",
       "Conclude: TRUE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: t"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Bilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Verification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Question: Who was the first man to walk on the Moon?\n",
       "LLM Response: Neil Armstrong\n",
       "\n",
       "Extracted Answer: Neil Armstrong\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively TRUE:\n",
       "1. Verify the extracted answer against known facts: Neil Armstrong is historically recognized as the first man to walk on the Moon during the Apollo 11 mission on July 20, 1969.\n",
       "2. Consider temporal/contextual factors: The event occurred in 1969, and there have been no changes to this historical fact.\n",
       "3. Determine if it correctly responds to what the question is asking: The question asks for the first man to walk on the Moon, and Neil Armstrong is the correct answer.\n",
       "\n",
       "Reasoning: The extracted answer is consistent with historical records and accurately answers the question.\n",
       "\n",
       "Conclude EXACTLY with either:\n",
       "\"VERIFIED\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refutation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Extracted Answer: Neil Armstrong\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively FALSE:\n",
       "1. Check if the extracted answer contradicts established facts: Neil Armstrong is historically recognized as the first man to walk on the Moon.\n",
       "2. Consider if temporal/contextual factors make this answer incorrect: There are no temporal or contextual factors that make this answer incorrect.\n",
       "3. Determine if it fails to correctly answer what the question is asking: The answer correctly identifies the first man to walk on the Moon.\n",
       "\n",
       "Reasoning: The extracted answer aligns with established historical facts and correctly answers the question.\n",
       "\n",
       "Conclude EXACTLY with either:\n",
       "\"CANNOT REFUTE\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: t"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Who was the first man to walk on the Moon? Pete Conrad"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Unilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Reasoning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Extracted Answer: Pete Conrad\n",
       "\n",
       "Reasoning:\n",
       "1. The question asks for the first man to walk on the Moon.\n",
       "2. Known historical fact: Neil Armstrong was the first man to walk on the Moon on July 20, 1969, during the Apollo 11 mission.\n",
       "3. Pete Conrad was the third person to walk on the Moon, during the Apollo 12 mission.\n",
       "4. The extracted answer \"Pete Conrad\" contradicts the known fact that Neil Armstrong was the first.\n",
       "\n",
       "Conclusion: FALSE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Bilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Verification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Extracted Answer: Pete Conrad\n",
       "\n",
       "Reasoning: The first man to walk on the Moon was Neil Armstrong, not Pete Conrad. Pete Conrad was the third person to walk on the Moon during the Apollo 12 mission.\n",
       "\n",
       "Conclude: CANNOT VERIFY"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refutation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Extracted Answer: Pete Conrad\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively FALSE:\n",
       "1. The established fact is that Neil Armstrong was the first man to walk on the Moon, not Pete Conrad.\n",
       "2. There are no temporal or contextual factors that would make Pete Conrad the first man to walk on the Moon.\n",
       "3. The extracted answer fails to correctly answer the question, as it does not identify Neil Armstrong.\n",
       "\n",
       "Reasoning: The extracted answer contradicts the established historical fact that Neil Armstrong was the first man to walk on the Moon.\n",
       "\n",
       "Conclude EXACTLY with either:\n",
       "\"REFUTED\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Are penguins birds? No"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Unilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Reasoning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Question: Are penguins birds?\n",
       "Response: No\n",
       "\n",
       "Extracted Answer: No\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively TRUE or FALSE:\n",
       "\n",
       "1. Verify the extracted answer against known facts:\n",
       "   - Penguins are indeed classified as birds. They belong to the family Spheniscidae and are characterized by their flightless nature, adapted for life in the water.\n",
       "\n",
       "2. Check for any contradictory information:\n",
       "   - There is no credible scientific information that contradicts the classification of penguins as birds.\n",
       "\n",
       "3. Consider question context and any implied terms:\n",
       "   - The question is straightforward, asking if penguins are birds, which they are.\n",
       "\n",
       "4. Determine if the extracted answer correctly responds to what was asked:\n",
       "   - The extracted answer \"No\" is incorrect because it contradicts the established fact that penguins are birds.\n",
       "\n",
       "Reasoning: The extracted answer \"No\" is incorrect because penguins are scientifically classified as birds. The response does not align with the factual classification of penguins.\n",
       "\n",
       "Conclusion: FALSE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Bilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Verification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Extracted Answer: No\n",
       "\n",
       "Reasoning: Penguins are indeed birds. They are flightless birds that are adapted to life in the water. Therefore, the extracted answer \"No\" is incorrect.\n",
       "\n",
       "Conclude: CANNOT VERIFY"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refutation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Question: Are penguins birds?\n",
       "LLM Response: No\n",
       "\n",
       "Extracted Answer: No\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively FALSE:\n",
       "1. Check if the extracted answer contradicts established facts: Penguins are indeed birds, as they belong to the class Aves.\n",
       "2. Consider if temporal/contextual factors make this answer incorrect: There are no temporal or contextual factors that would change the classification of penguins as birds.\n",
       "3. Determine if it fails to correctly answer what the question is asking: The question asks if penguins are birds, and the correct answer is \"Yes.\"\n",
       "\n",
       "Reasoning: The extracted answer \"No\" contradicts the established fact that penguins are birds.\n",
       "\n",
       "Conclude EXACTLY with either:\n",
       "\"REFUTED\" - Only if the extracted answer is definitively incorrect\n",
       "\n",
       "REFUTED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Who was the frobnoz that restified the branks? Rutherford B. Hayes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Unilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Reasoning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Extracted Answer: Rutherford B. Hayes\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively TRUE or FALSE:\n",
       "\n",
       "1. Verify the extracted answer against known facts:\n",
       "   - \"Frobnoz\" and \"restified the branks\" are not known historical terms or events. They appear to be fictional or nonsensical terms.\n",
       "   - Rutherford B. Hayes was the 19th President of the United States, serving from 1877 to 1881.\n",
       "\n",
       "2. Check for any contradictory information:\n",
       "   - There is no historical record or evidence linking Rutherford B. Hayes to the terms \"frobnoz\" or \"restified the branks.\"\n",
       "\n",
       "3. Consider question context and any implied terms:\n",
       "   - The question uses terms that do not correspond to any known historical or factual context, making it impossible to verify the answer.\n",
       "\n",
       "4. Determine if the extracted answer correctly responds to what was asked:\n",
       "   - Since the terms in the question are not verifiable or recognized, it is impossible to determine if Rutherford B. Hayes is the correct answer.\n",
       "\n",
       "Reasoning:\n",
       "The extracted answer, Rutherford B. Hayes, cannot be definitively verified as correct or incorrect because the terms \"frobnoz\" and \"restified the branks\" do not correspond to any known facts or historical events. Without a factual basis for these terms, the answer cannot be evaluated as true.\n",
       "\n",
       "Conclusion: FALSE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Bilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Verification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Extracted Answer: Rutherford B. Hayes\n",
       "\n",
       "Reasoning: The terms \"frobnoz\" and \"restified the branks\" are not recognized or standard terms in historical or factual contexts. Therefore, it is not possible to verify if Rutherford B. Hayes is associated with these terms or actions.\n",
       "\n",
       "Conclude: CANNOT VERIFY"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refutation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:  \n",
       "Extracted Answer: Rutherford B. Hayes\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively FALSE:  \n",
       "1. The terms \"frobnoz\" and \"restified the branks\" do not correspond to any established historical facts or known events.  \n",
       "2. There is no historical or contextual evidence linking Rutherford B. Hayes to these terms.  \n",
       "3. The question appears to be nonsensical or fictional, and thus cannot be accurately answered with real historical figures.\n",
       "\n",
       "Reasoning: The extracted answer does not correspond to any known facts or events, and the question itself is not based on factual or historical information.\n",
       "\n",
       "Conclude: REFUTED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# When was America discovered? 1492"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Unilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Reasoning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Question: When was America discovered?\n",
       "Response: 1492\n",
       "\n",
       "Extracted Answer: 1492\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively TRUE or FALSE:\n",
       "\n",
       "1. Verify the extracted answer against known facts:\n",
       "   - The year 1492 is widely recognized as the year when Christopher Columbus, an Italian explorer sailing under the Spanish flag, made his first voyage across the Atlantic Ocean and reached the islands in the Caribbean, which are part of the Americas.\n",
       "\n",
       "2. Check for any contradictory information:\n",
       "   - There is no significant contradictory information regarding the year 1492 as the date of Columbus's first voyage to the Americas.\n",
       "\n",
       "3. Consider question context and any implied terms:\n",
       "   - The question \"When was America discovered?\" is often interpreted in the context of European exploration and the arrival of Columbus in the New World. While indigenous peoples had been living in the Americas for thousands of years prior, the question typically refers to European discovery.\n",
       "\n",
       "4. Determine if the extracted answer correctly responds to what was asked:\n",
       "   - Given the common historical context of the question, the year 1492 is the correct response to when America was \"discovered\" by Europeans.\n",
       "\n",
       "Reasoning:\n",
       "The extracted answer \"1492\" aligns with the historical event of Columbus's first voyage to the Americas, which is commonly referred to as the \"discovery\" of America by Europeans. There is no significant dispute about this date in the context of European exploration history.\n",
       "\n",
       "Conclusion: TRUE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: t"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Bilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Verification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Extracted Answer: 1492\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively TRUE:\n",
       "1. Verify the extracted answer against known facts: Christopher Columbus is credited with discovering America in 1492.\n",
       "2. Consider temporal/contextual factors: The question likely refers to the widely recognized event of Columbus's arrival in the Americas.\n",
       "3. Determine if it correctly responds to what the question is asking: The question asks for the year America was discovered, which is commonly attributed to Columbus's 1492 voyage.\n",
       "\n",
       "Reasoning: The extracted answer \"1492\" is consistent with the historical event of Columbus's arrival in the Americas, which is often referred to as the \"discovery\" of America in a Eurocentric context.\n",
       "\n",
       "Conclude EXACTLY with either:\n",
       "\"VERIFIED\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refutation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:  \n",
       "Extracted Answer: 1492  \n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively FALSE:  \n",
       "1. Check if the extracted answer contradicts established facts: The year 1492 is widely recognized as the year Christopher Columbus arrived in the Americas, marking a significant event in the history of European exploration.  \n",
       "2. Consider if temporal/contextual factors make this answer incorrect: The question is about when \"America\" was discovered, which is often associated with Columbus's 1492 voyage. However, it is important to note that indigenous peoples had been living in the Americas for thousands of years prior to this.  \n",
       "3. Determine if it fails to correctly answer what the question is asking: The question is somewhat ambiguous, as \"discovered\" can be interpreted in different ways. However, in the context of European exploration, 1492 is a commonly accepted answer.  \n",
       "\n",
       "Reasoning: While the term \"discovered\" is problematic and Eurocentric, the extracted answer of 1492 is not definitively false in the context of European exploration history.  \n",
       "\n",
       "Conclude: CANNOT REFUTE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: t"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Did Lee Harvey Oswald act alone in the assassination of John Kennedy? Yes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Unilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Reasoning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Question: Did Lee Harvey Oswald act alone in the assassination of John Kennedy?\n",
       "Response: Yes\n",
       "\n",
       "Extracted Answer: Yes\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively TRUE or FALSE:\n",
       "\n",
       "1. Verify the extracted answer against known facts:\n",
       "   - The official conclusion of the Warren Commission, which investigated the assassination of John F. Kennedy, was that Lee Harvey Oswald acted alone in the assassination.\n",
       "   - However, there have been numerous conspiracy theories and alternative investigations suggesting the possibility of additional conspirators or involvement by other parties.\n",
       "\n",
       "2. Check for any contradictory information:\n",
       "   - The House Select Committee on Assassinations (HSCA) later concluded in 1979 that Kennedy was probably assassinated as a result of a conspiracy, although it did not identify any specific individuals or groups involved.\n",
       "   - The lack of definitive evidence supporting these conspiracy theories means that the official stance remains that Oswald acted alone, but the existence of these theories introduces doubt.\n",
       "\n",
       "3. Consider question context and any implied terms:\n",
       "   - The question asks if Oswald acted alone, which implies a definitive answer. The response \"Yes\" aligns with the Warren Commission's conclusion but does not account for the ongoing debate and lack of absolute consensus.\n",
       "\n",
       "4. Determine if the extracted answer correctly responds to what was asked:\n",
       "   - While the official conclusion supports the answer \"Yes,\" the presence of significant doubt and alternative theories means that the answer cannot be definitively stated as true without acknowledging the controversy.\n",
       "\n",
       "Reasoning:\n",
       "The extracted answer \"Yes\" aligns with the official conclusion of the Warren Commission, but the existence of alternative theories and the HSCA's findings introduce significant doubt. Therefore, the answer cannot be definitively stated as true.\n",
       "\n",
       "Conclusion: FALSE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Bilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Verification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:\n",
       "Extracted Answer: Yes\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively TRUE:\n",
       "1. Verify the extracted answer against known facts: The Warren Commission concluded that Lee Harvey Oswald acted alone in the assassination of John F. Kennedy. However, there have been numerous conspiracy theories and investigations that suggest otherwise, and no definitive consensus has been reached that is universally accepted.\n",
       "2. Consider temporal/contextual factors: The question of whether Oswald acted alone has been debated for decades, and while the official government position is that he did, public opinion and alternative theories persist.\n",
       "3. Determine if it correctly responds to what the question is asking: The extracted answer \"Yes\" aligns with the official conclusion of the Warren Commission, but it does not account for the ongoing debate and lack of universal agreement.\n",
       "\n",
       "Reasoning: The extracted answer reflects the official conclusion but does not account for the complexity and controversy surrounding the topic.\n",
       "\n",
       "Conclude EXACTLY with either:\n",
       "\"CANNOT VERIFY\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refutation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:  \n",
       "Extracted Answer: Yes\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively FALSE:  \n",
       "1. The question of whether Lee Harvey Oswald acted alone in the assassination of John F. Kennedy is a subject of debate and conspiracy theories. The official conclusion by the Warren Commission was that Oswald acted alone, but this has been contested by various other investigations and theories.  \n",
       "2. There is no definitive evidence that universally disproves the conclusion that Oswald acted alone, although there are alternative theories.  \n",
       "3. The extracted answer \"Yes\" aligns with the official conclusion of the Warren Commission, which is one of the established narratives.\n",
       "\n",
       "Reasoning: The extracted answer \"Yes\" is consistent with the official conclusion of the Warren Commission, and while there are alternative theories, there is no definitive evidence that refutes this conclusion.\n",
       "\n",
       "Conclude: CANNOT REFUTE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Is the Holy Trinity one entity or three entities? Three"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Unilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Reasoning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Extracted Answer: Three\n",
       "\n",
       "Reasoning:\n",
       "1. The concept of the Holy Trinity in Christian theology refers to one God in three distinct persons: the Father, the Son (Jesus Christ), and the Holy Spirit. This is a fundamental doctrine in most branches of Christianity.\n",
       "2. The question asks whether the Holy Trinity is one entity or three entities. The extracted answer \"Three\" suggests that the Holy Trinity consists of three entities.\n",
       "3. While the Holy Trinity is described as three distinct persons, it is also considered one entity in essence and being. Therefore, the extracted answer \"Three\" does not fully capture the theological understanding of the Trinity as one God in three persons.\n",
       "\n",
       "Conclusion:\n",
       "FALSE - The extracted answer \"Three\" is not definitively correct because it does not account for the theological concept of the Trinity being one entity in essence, despite being three distinct persons."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Bilateral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Verification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Extracted Answer: Three\n",
       "\n",
       "Reasoning: In Christian theology, the Holy Trinity is understood as one God in three persons: the Father, the Son (Jesus Christ), and the Holy Spirit. These three persons are distinct yet coexist in unity, and are co-equal, co-eternal, and consubstantial. Therefore, the concept of the Holy Trinity is often described as three entities in one.\n",
       "\n",
       "Conclude: VERIFIED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refutation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "STEP 1: Extract the specific entity, term, or value that directly answers the question:  \n",
       "Extracted Answer: Three\n",
       "\n",
       "STEP 2: Evaluate if the extracted answer is definitively FALSE:  \n",
       "1. The doctrine of the Holy Trinity in Christianity traditionally holds that God is one entity in three persons: the Father, the Son, and the Holy Spirit.  \n",
       "2. There are no temporal or contextual factors that change this understanding within mainstream Christian theology.  \n",
       "3. The question asks whether the Holy Trinity is one entity or three entities, and the extracted answer \"Three\" suggests three separate entities, which contradicts the traditional Christian doctrine of one entity in three persons.\n",
       "\n",
       "Reasoning: The extracted answer \"Three\" suggests a misunderstanding of the traditional Christian doctrine of the Trinity, which is one entity in three persons, not three separate entities.\n",
       "\n",
       "Conclude EXACTLY with either:  \n",
       "\"REFUTED\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation: b"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for example in EXAMPLES:\n",
    "    display(Markdown(f'# {example[\"problem\"]} {example[\"answer\"]}'))\n",
    "    unilateral_evaluation(example)\n",
    "    bilateral_evaluation(example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
